{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d717d-2ff5-46af-b7ee-52b45a745f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify,request\n",
    "import pickle\n",
    "import nltk                                # Natural Language Toolkit library\n",
    "from nltk.corpus import twitter_samples    # Example Twitter dataset from NLTK\n",
    "from nltk.corpus import stopwords          # Built-in list of common stopwords\n",
    "from nltk.stem import PorterStemmer        # Stemmer for reducing words\n",
    "from nltk.stem import WordNetLemmatizer    # Lemmatizer to get base form of words\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import re\n",
    "import string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#*************************************************************************************#\n",
    "# load pre-trained Logistic Regression model\n",
    "with open('logistic_regression_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# loading the fitted vectorizer\n",
    "with open('vectorizer.pkl', 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)\n",
    "    \n",
    "# Custom text preprocessing pipeline\n",
    "def process_tweet(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)          # remove stock market tickers like $AAPL\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)       # remove retweet tag \"RT\"\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)    # remove hyperlinks\n",
    "    tweet = re.sub(r'#', '', tweet)                      # remove hashtag symbol\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  #  ignore stopwords\n",
    "                word not in string.punctuation):  # ignore punctuation\n",
    "            lemma_word = lemmatizer.lemmatize(word,pos='v')  # lemmatize word as verb\n",
    "            tweets_clean.append(lemma_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "\n",
    "\n",
    "# convert list of words back to string\n",
    "def list_to_string(lst):\n",
    "    return ' '.join(lst)\n",
    "#****************************************************************************************#\n",
    "\n",
    "@app.route('/prediction', methods=['POST'])\n",
    "def predicting_sentiment():\n",
    "\n",
    "    # get input JSON payload\n",
    "    data = request.get_json()\n",
    "\n",
    "    input_string = data['input_string']\n",
    "\n",
    "    # step 1: text preprocessing\n",
    "    tokenize_data = process_tweet(input_string)\n",
    "\n",
    "   # step 2: join tokens into single string\n",
    "    final_string = list_to_string(tokenize_data)\n",
    "\n",
    "   # step 3: convert text into vector form\n",
    "    text_vector = loaded_vectorizer.transform([final_string])\n",
    "\n",
    "    # step 4: perform sentiment prediction\n",
    "    prediction = loaded_model.predict(text_vector)\n",
    "    sentiment_mapping = {0: 'Negative', 1: 'Positive'}\n",
    "    predicted_sentiment = sentiment_mapping[prediction[0]]\n",
    "\n",
    "    return jsonify({'result': predicted_sentiment}), 200\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/status', methods=['GET'])\n",
    "def status():\n",
    "    return jsonify({'message': 'working NOW'}), 200\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
